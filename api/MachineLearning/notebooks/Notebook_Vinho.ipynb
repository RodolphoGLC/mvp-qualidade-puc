{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlcoelho/mvp-qualidade/blob/master/MVP3_MeuColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otEdveLq8Hn0"
      },
      "source": [
        "# MVP Sprint: Qualidade de Software, Segurança e Sistemas Inteligentes\n",
        "### Prática de Machine Learning em Python\n",
        "##### Problema. Saber a qualidade do vinho a partir dos parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EcX1jtd1pSt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smz5BnMhX5D7"
      },
      "source": [
        "## Imports para criação e treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCn8CH4M7wF-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.3.0)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%pip install seaborn\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import seaborn as sns\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcB0Efd-MS4"
      },
      "source": [
        "## Carga do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "29AFuCPtvG_i",
        "outputId": "47232767-1738-4d5d-c995-46e2882dd302"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed_acidity</th>\n",
              "      <th>volatile_acidity</th>\n",
              "      <th>citric_acid</th>\n",
              "      <th>residual_sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free_sulfur_dioxide</th>\n",
              "      <th>total_sulfur_dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  \n",
              "4      9.4        5  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/RodolphoGLC/teste/refs/heads/main/winequality-red.csv\"\n",
        "\n",
        "dataset = pd.read_csv(url, delimiter=',')\n",
        "\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOQajZ_Yf66U"
      },
      "source": [
        "## Exploração dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6VQaeX_f4GO",
        "outputId": "0dc5d10f-da3c-46ca-f571-755341137ef4"
      },
      "outputs": [],
      "source": [
        "def get_df_info(df, nome=\"DataFrame\"):\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\033[1m📊 Análise do {nome}:\\033[0m\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\n🔹 \\033[1mFormato:\\033[0m {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
        "    \n",
        "    print(f\"\\n🔹 \\033[1mColunas:\\033[0m {df.columns.to_list()}\")\n",
        "\n",
        "    print(f\"\\n🔹 \\033[1mValores Nulos por Coluna:\\033[0m\")\n",
        "    nulls = df.isnull().sum()\n",
        "    nulls = nulls[nulls > 0]\n",
        "    if nulls.empty:\n",
        "        print(\"\\n✅ Nenhum valor nulo encontrado.\")\n",
        "    else:\n",
        "        print(nulls)\n",
        "\n",
        "    print(f\"\\n🔹 \\033[1mEstatísticas Descritivas (Numéricas):\\033[0m\\n\")\n",
        "    print(df.describe().transpose())\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # (Opcional) Visualizações rápidas - comente se não quiser\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if dataset.isnull().sum().sum() == 0:\n",
        "        print(\"\\n✅ Nenhum valor nulo encontrado.\\n\")\n",
        "    else:\n",
        "        sns.heatmap(dataset.isnull(), cbar=False, cmap=\"coolwarm\")\n",
        "        plt.title(\"\\nMapa de calor dos valores nulos\")\n",
        "        plt.show()\n",
        "\n",
        "get_df_info(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " quality  quantidade  percentual (%)\n",
            "       3          10            0.63\n",
            "       4          53            3.31\n",
            "       5         681           42.59\n",
            "       6         638           39.90\n",
            "       7         199           12.45\n",
            "       8          18            1.13\n"
          ]
        }
      ],
      "source": [
        "# Converte em porcentagem\n",
        "contagem = dataset['quality'].value_counts().sort_index()\n",
        "\n",
        "# Contagem relativa (em %)\n",
        "percentual = (contagem / contagem.sum() * 100).round(2)\n",
        "\n",
        "# Cria um DataFrame combinado\n",
        "distribuicao = pd.DataFrame({\n",
        "    'quality': contagem.index,\n",
        "    'quantidade': contagem.values,\n",
        "    'percentual (%)': percentual.values\n",
        "})\n",
        "\n",
        "print(distribuicao.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE4-PIaTAfKX"
      },
      "source": [
        "## Pré Processamento e separação em conjunto de treino e conjunto de teste com holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fEiAm3LEAfPt"
      },
      "outputs": [],
      "source": [
        "test_size = 0.20 # tamanho do conjunto de teste\n",
        "seed = 202507 # semente aleatória\n",
        "\n",
        "array = dataset.values\n",
        "\n",
        "# Divide o DataFrame em (X) e (y)\n",
        "X = array[:,0:11]\n",
        "y = array[:,11]\n",
        "\n",
        "\n",
        "# Separação em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "    test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação\n",
        "\n",
        "# Parâmetros e partições da validação cruzada\n",
        "scoring = 'accuracy'\n",
        "num_particoes = 10\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # validação cruzada com estratificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OGe0DtAfU4"
      },
      "source": [
        "## Modelagem e Inferência"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHzQpbX9QQh"
      },
      "source": [
        "### Criação e avaliação de modelos: linha base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: 0.580149 (0.032855)\n",
            "KNN: 0.496487 (0.048866)\n",
            "CART: 0.590262 (0.027811)\n",
            "NB: 0.534787 (0.030973)\n",
            "SVM: 0.500443 (0.033271)\n",
            "Bagging: 0.676316 (0.018088)\n",
            "RF: 0.685698 (0.033959)\n",
            "ET: 0.677867 (0.031076)\n",
            "Ada: 0.496494 (0.044762)\n",
            "GB: 0.640354 (0.038490)\n",
            "Voting: 0.594230 (0.022750)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "np.random.seed(202507) # definindo uma semente global\n",
        "\n",
        "# Lista que armazenará os modelos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('LR', LogisticRegression(max_iter=200))) \n",
        "models.append(('KNN', KNeighborsClassifier())) \n",
        "models.append(('CART', DecisionTreeClassifier())) \n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
        "base = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Criando os modelos para o VotingClassifier\n",
        "bases = []\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "bases.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "bases.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "bases.append(('svm', model3))\n",
        "\n",
        "# Criando os ensembles e adicionando-os na lista de modelos\n",
        "models.append(('Bagging', BaggingClassifier(estimator=base, n_estimators=num_trees)))\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
        "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
        "models.append(('Voting', VotingClassifier(bases)))\n",
        "\n",
        "# Listas para armazenar os resultados\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliação dos modelos (treinamento)\n",
        "for name, model in models:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(15,10)) \n",
        "fig.suptitle('Comparação dos Modelos') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ao rodar o codigo acima, percebemos que o melhor foi o RF\n",
        " -> Acurácia média: 0.685698\n",
        " -> Desvio padrão: 0.033959\n",
        " -> No boxplot: apresenta mediana alta, variância controlada e poucos outliers.\n",
        "\n",
        "Também apresenta bons resultados nos modelos ET, Bagging e GB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olo7SPk2BvvW"
      },
      "source": [
        "### Criação e avaliação de modelos: dados padronizados e normalizados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(202507) # definindo uma semente global para este bloco\n",
        "\n",
        "# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "\n",
        "# Algoritmos que serão utilizados\n",
        "reg_log = ('LR', LogisticRegression(max_iter=200))\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "naive_bayes = ('NB', GaussianNB())\n",
        "svm = ('SVM', SVC())\n",
        "bagging = ('Bag', BaggingClassifier(estimator=base, n_estimators=num_trees))\n",
        "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "extra_trees = ('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "adaboost = ('Ada', AdaBoostClassifier(n_estimators=num_trees))\n",
        "gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))\n",
        "voting = ('Voting', VotingClassifier(bases))\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Montando os pipelines\n",
        "\n",
        "# Dataset original\n",
        "pipelines.append(('LR-orig', Pipeline([reg_log]))) \n",
        "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
        "pipelines.append(('CART-orig', Pipeline([cart])))\n",
        "pipelines.append(('NB-orig', Pipeline([naive_bayes])))\n",
        "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
        "pipelines.append(('Bag-orig', Pipeline([bagging])))\n",
        "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
        "pipelines.append(('ET-orig', Pipeline([extra_trees])))\n",
        "pipelines.append(('Ada-orig', Pipeline([adaboost])))\n",
        "pipelines.append(('GB-orig', Pipeline([gradient_boosting])))\n",
        "pipelines.append(('Vot-orig', Pipeline([voting])))\n",
        "\n",
        "# Dataset Padronizado\n",
        "pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log]))) \n",
        "pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))\n",
        "pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))\n",
        "pipelines.append(('Bag-padr', Pipeline([standard_scaler, bagging]))) \n",
        "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
        "pipelines.append(('ET-padr', Pipeline([standard_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-padr', Pipeline([standard_scaler, adaboost])))\n",
        "pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-padr', Pipeline([standard_scaler, voting])))\n",
        "\n",
        "# Dataset Normalizado\n",
        "pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log]))) \n",
        "pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))\n",
        "pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))\n",
        "pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))\n",
        "pipelines.append(('Bag-norm', Pipeline([min_max_scaler, bagging]))) \n",
        "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
        "pipelines.append(('ET-norm', Pipeline([min_max_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-norm', Pipeline([min_max_scaler, adaboost])))\n",
        "pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-norm', Pipeline([min_max_scaler, voting])))\n",
        "\n",
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Após rodar esse trecho obtive os seguintes resultados:\n",
        "\n",
        "Tipo - Melhor Modelo - Acurácia Média (± Desvio)\n",
        "orig - RF (Random Forest) - 0.686 ± 0.034\n",
        "padr - ET (Extra Trees) - 0.684 ± 0.030\n",
        "norm - ET (Extra Trees) - 0.689 ± 0.034\n",
        "\n",
        "Decidi seguir com o modelo do BaggingClassifier padr, mesmo não sendo o que teve a maior acuracia\n",
        "\n",
        "Resolvi seguir por esse caminho, devido a velocidade. Pq quando testei com os outros no local acabou gerando um atraso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(202507)  # Definindo uma semente global para este bloco\n",
        "\n",
        "# Lista de modelos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('LR', LogisticRegression(max_iter=200))) \n",
        "models.append(('KNN', KNeighborsClassifier())) \n",
        "models.append(('CART', DecisionTreeClassifier())) \n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
        "base = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Criando os modelos para o VotingClassifier\n",
        "bases = []\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "bases.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "bases.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "bases.append(('svm', model3))\n",
        "\n",
        "# Criando os ensembles e adicionando-os na lista de modelos\n",
        "models.append(('Bagging', BaggingClassifier(estimator=base, n_estimators=num_trees)))\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
        "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
        "models.append(('Voting', VotingClassifier(estimators=bases, voting='hard')))\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Lista de pipelines\n",
        "pipelines = []\n",
        "\n",
        "# Criando pipelines para cada modelo\n",
        "for name, model in models:\n",
        "    pipelines.append((name + '-orig', Pipeline(steps=[(name, model)])))\n",
        "    pipelines.append((name + '-padr', Pipeline(steps=[standard_scaler, (name, model)])))\n",
        "    pipelines.append((name + '-norm', Pipeline(steps=[min_max_scaler, (name, model)])))\n",
        "\n",
        "# Definindo os parâmetros para GridSearchCV\n",
        "param_grids = {\n",
        "    'LR': {\n",
        "        'LR__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'LR__solver': ['liblinear', 'saga']\n",
        "    },\n",
        "    'KNN': {\n",
        "        'KNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
        "        'KNN__metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
        "    },\n",
        "    'CART': {\n",
        "        'CART__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "        'CART__min_samples_split': [2, 5, 10],\n",
        "        'CART__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    'NB': {\n",
        "        'NB__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'SVM__C': [0.1, 1, 10, 100],\n",
        "        'SVM__gamma': [1, 0.1, 0.01, 0.001],\n",
        "    },\n",
        "    'RF': {\n",
        "        'RF__n_estimators': [10, 50, 100, 200],\n",
        "        'RF__max_features': ['auto', 'sqrt', 'log2'],\n",
        "        'RF__max_depth': [None, 10, 20, 30],\n",
        "        'RF__min_samples_split': [2, 5, 10],\n",
        "        'RF__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    'ET': {\n",
        "        'ET__n_estimators': [10, 50, 100, 200],\n",
        "        'ET__max_features': ['auto', 'sqrt', 'log2'],\n",
        "        'ET__max_depth': [None, 10, 20, 30],\n",
        "        'ET__min_samples_split': [2, 5, 10],\n",
        "        'ET__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    'Ada': {\n",
        "        'Ada__n_estimators': [10, 50, 100, 200],\n",
        "        'Ada__learning_rate': [0.01, 0.1, 1, 10]\n",
        "    },\n",
        "    'GB': {\n",
        "        'GB__n_estimators': [10, 50, 100, 200],\n",
        "        'GB__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "        'GB__max_depth': [3, 5, 7, 9]\n",
        "    },\n",
        "    'Voting': {}\n",
        "}\n",
        "\n",
        "# Parâmetros de cross-validation e scoring\n",
        "scoring = 'accuracy'\n",
        "kfold = 5\n",
        "\n",
        "# Executando o GridSearchCV para cada pipeline\n",
        "for name, pipeline in pipelines:\n",
        "    model_type = name.split('-')[0]\n",
        "    if model_type in param_grids:\n",
        "        param_grid = param_grids[model_type]\n",
        "    else:\n",
        "        param_grid = {}  # Para modelos que não têm parâmetros definidos\n",
        "\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # Imprimindo a melhor configuração\n",
        "    print(\"Modelo: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo: Bagging-orig - Melhor: 0.676317 usando {}\n",
        "\n",
        "Os modelos depois de testar com todos os hiperparametros, pecebi que houve uma melhora com eles, porém para os casos dos Bagging, RF, ET, Ada, GB e Voting sem usar nenhum parametro ou usando acaba gerando um ganho muito pequeno e gera uma maior demora para rodar o projeto. Então visto custo (tempo x acuracia), decidi usar o mais simples para fins de facilitar no trabalho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Otimização com hiperparâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: Ada-orig - Melhor: 0.5676 usando {'Ada__learning_rate': 0.1, 'Ada__n_estimators': 50}\n",
            "Modelo: Ada-padr - Melhor: 0.5676 usando {'Ada__learning_rate': 0.1, 'Ada__n_estimators': 50}\n",
            "Modelo: Ada-norm - Melhor: 0.5676 usando {'Ada__learning_rate': 0.1, 'Ada__n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "pipeline_ada_orig = Pipeline(steps=[('Ada', AdaBoostClassifier())])\n",
        "pipeline_ada_padr = Pipeline(steps=[('StandardScaler', StandardScaler()), ('Ada', AdaBoostClassifier())])\n",
        "pipeline_ada_norm = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('Ada', AdaBoostClassifier())])\n",
        "\n",
        "param_grid_ada = {\n",
        "    'Ada__n_estimators': [10, 50, 100, 200],\n",
        "    'Ada__learning_rate': [0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "for pipeline, label in zip([pipeline_ada_orig, pipeline_ada_padr, pipeline_ada_norm], ['orig', 'padr', 'norm']):\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid_ada, scoring='accuracy', cv=5)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Modelo: Ada-{label} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "pipeline_rf_orig = Pipeline(steps=[('RF', RandomForestClassifier())])\n",
        "pipeline_rf_padr = Pipeline(steps=[('StandardScaler', StandardScaler()), ('RF', RandomForestClassifier())])\n",
        "pipeline_rf_norm = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('RF', RandomForestClassifier())])\n",
        "\n",
        "param_grid_rf = {\n",
        "    'RF__n_estimators': [10, 50, 100, 200],\n",
        "    'RF__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'RF__max_depth': [None, 10, 20, 30],\n",
        "    'RF__min_samples_split': [2, 5, 10],\n",
        "    'RF__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "for pipeline, label in zip([pipeline_rf_orig, pipeline_rf_padr, pipeline_rf_norm], ['orig', 'padr', 'norm']):\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid_rf, scoring='accuracy', cv=5)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Modelo: RF-{label} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: LR-orig - Melhor: 0.5864 usando {'LR__C': 100, 'LR__solver': 'liblinear'}\n",
            "Modelo: LR-padr - Melhor: 0.6005 usando {'LR__C': 0.1, 'LR__solver': 'saga'}\n",
            "Modelo: LR-norm - Melhor: 0.5981 usando {'LR__C': 10, 'LR__solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "# Otimização LR - Logistic Regression\n",
        "pipeline_lr_orig = Pipeline(steps=[('LR', LogisticRegression(max_iter=200))])\n",
        "pipeline_lr_padr = Pipeline(steps=[('StandardScaler', StandardScaler()), ('LR', LogisticRegression(max_iter=200))])\n",
        "pipeline_lr_norm = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('LR', LogisticRegression(max_iter=200))])\n",
        "\n",
        "param_grid_lr = {\n",
        "    'LR__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'LR__solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "for pipeline, label in zip([pipeline_lr_orig, pipeline_lr_padr, pipeline_lr_norm], ['orig', 'padr', 'norm']):\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid_lr, scoring='accuracy', cv=5)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Modelo: LR-{label} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do CART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: CART-orig - Melhor: 0.5966 usando {'CART__max_depth': 20, 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n",
            "Modelo: CART-padr - Melhor: 0.5981 usando {'CART__max_depth': None, 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n",
            "Modelo: CART-norm - Melhor: 0.6013 usando {'CART__max_depth': 50, 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "pipeline_cart_orig = Pipeline(steps=[('CART', DecisionTreeClassifier())])\n",
        "pipeline_cart_padr = Pipeline(steps=[('StandardScaler', StandardScaler()), ('CART', DecisionTreeClassifier())])\n",
        "pipeline_cart_norm = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('CART', DecisionTreeClassifier())])\n",
        "\n",
        "param_grid_cart = {\n",
        "    'CART__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'CART__min_samples_split': [2, 5, 10],\n",
        "    'CART__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "for pipeline, label in zip([pipeline_cart_orig, pipeline_cart_padr, pipeline_cart_norm], ['orig', 'padr', 'norm']):\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid_cart, scoring='accuracy', cv=5)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Modelo: CART-{label} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: Bagging-orig - Melhor: 0.6826 usando {}\n",
            "Modelo: Bagging-padr - Melhor: 0.6615 usando {}\n",
            "Modelo: Bagging-norm - Melhor: 0.6748 usando {}\n"
          ]
        }
      ],
      "source": [
        "base_estimator = DecisionTreeClassifier()\n",
        "pipeline_bagging_orig = Pipeline(steps=[('Bagging', BaggingClassifier(estimator=base_estimator, n_estimators=100))])\n",
        "pipeline_bagging_padr = Pipeline(steps=[('StandardScaler', StandardScaler()), ('Bagging', BaggingClassifier(estimator=base_estimator, n_estimators=100))])\n",
        "pipeline_bagging_norm = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('Bagging', BaggingClassifier(estimator=base_estimator, n_estimators=100))])\n",
        "\n",
        "# Sem parâmetros para ajustar neste caso\n",
        "param_grid_bagging = {}\n",
        "\n",
        "for pipeline, label in zip([pipeline_bagging_orig, pipeline_bagging_padr, pipeline_bagging_norm], ['orig', 'padr', 'norm']):\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid_bagging, scoring='accuracy', cv=5)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Modelo: Bagging-{label} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBSDgpXNt1Fp",
        "outputId": "579ed35a-c508-4730-d993-d01914fddf5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado: knn-orig - Melhor: 0.574705 usando {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 1}\n",
            "Resultado: knn-padr - Melhor: 0.623161 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 1}\n",
            "Resultado: knn-norm - Melhor: 0.620011 usando {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 1}\n"
          ]
        }
      ],
      "source": [
        "# Tuning do KNN\n",
        "\n",
        "np.random.seed(202507) # definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('knn-orig', Pipeline(steps=[knn])))\n",
        "pipelines.append(('knn-padr', Pipeline(steps=[standard_scaler, knn])))\n",
        "pipelines.append(('knn-norm', Pipeline(steps=[min_max_scaler, knn])))\n",
        "\n",
        "param_grid = {\n",
        "    'KNN__n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],\n",
        "    'KNN__metric': [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
        "}\n",
        "\n",
        "# Prepara e executa o GridSearchCV\n",
        "for name, model in pipelines:\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Resultado: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94q4_Q9qxKO"
      },
      "source": [
        "#### Otimização do SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_s2QplqVGD",
        "outputId": "1c16162f-365a-4c59-a44e-7cca0a2e0055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado: svm-orig - Melhor: 0.580967 usando {'SVM__C': 100, 'SVM__gamma': 0.1}\n",
            "Resultado: svm-padr - Melhor: 0.646610 usando {'SVM__C': 1, 'SVM__gamma': 1}\n",
            "Resultado: svm-norm - Melhor: 0.598899 usando {'SVM__C': 100, 'SVM__gamma': 1}\n"
          ]
        }
      ],
      "source": [
        "# Tuning do SVM\n",
        "\n",
        "np.random.seed(202507) # definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "svm = ('SVM', SVC())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('svm-orig', Pipeline(steps=[svm])))\n",
        "pipelines.append(('svm-padr', Pipeline(steps=[standard_scaler, svm])))\n",
        "pipelines.append(('svm-norm', Pipeline(steps=[min_max_scaler, svm])))\n",
        "\n",
        "param_grid = {\n",
        "    'SVM__C': [0.1, 1, 10, 100],\n",
        "    'SVM__gamma': [1, 0.1, 0.01, 0.001]\n",
        "}\n",
        "\n",
        "# Prepara e executa o GridSearchCV\n",
        "for name, model in pipelines:\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Resultado: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AleaEcbERmT"
      },
      "source": [
        "#### Otimização do Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOY69ZQlEWZB",
        "outputId": "6122efda-6213-48a3-fe75-1d1a6ee68a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado: nb-orig - Melhor: 0.551193 usando {'NB__var_smoothing': 1e-05}\n",
            "Resultado: nb-padr - Melhor: 0.537906 usando {'NB__var_smoothing': 1e-09}\n",
            "Resultado: nb-norm - Melhor: 0.537906 usando {'NB__var_smoothing': 1e-09}\n"
          ]
        }
      ],
      "source": [
        "# Tuning do Gaussian Naive Bayes\n",
        "\n",
        "np.random.seed(202507) # definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "nb = ('NB', GaussianNB())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('nb-orig', Pipeline(steps=[nb])))\n",
        "pipelines.append(('nb-padr', Pipeline(steps=[standard_scaler, nb])))\n",
        "pipelines.append(('nb-norm', Pipeline(steps=[min_max_scaler, nb])))\n",
        "\n",
        "param_grid = {\n",
        "    'NB__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "}\n",
        "\n",
        "# Prepara e executa o GridSearchCV\n",
        "for name, model in pipelines:\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Resultado: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCyStNI_PIZ"
      },
      "source": [
        "#### Otimização da Árvore de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TKgalQT_WGW",
        "outputId": "6a276291-e638-47b8-d72b-518c271f697b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado: cart-orig - Melhor: 0.609849 usando {'CART__criterion': 'entropy', 'CART__max_depth': 50, 'CART__max_features': 'log2', 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n",
            "Resultado: cart-padr - Melhor: 0.616929 usando {'CART__criterion': 'entropy', 'CART__max_depth': None, 'CART__max_features': 'sqrt', 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n",
            "Resultado: cart-norm - Melhor: 0.623930 usando {'CART__criterion': 'gini', 'CART__max_depth': 50, 'CART__max_features': 'sqrt', 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "# Tuning da Árvore de Decisão\n",
        "# Utilizando hiperparâmetros: criterion, max_depth, min_samples_split, min_samples_leaf, max_features\n",
        "\n",
        "# Melhor Resultado: cart-norm - Melhor: 0.623930 usando {'CART__criterion': 'gini', 'CART__max_depth': 50, 'CART__max_features': 'sqrt', 'CART__min_samples_leaf': 1, 'CART__min_samples_split': 2}\n",
        "\n",
        "np.random.seed(202507) # definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('cart-orig', Pipeline(steps=[cart])))\n",
        "pipelines.append(('cart-padr', Pipeline(steps=[standard_scaler, cart])))\n",
        "pipelines.append(('cart-norm', Pipeline(steps=[min_max_scaler, cart])))\n",
        "\n",
        "param_grid = {\n",
        "    'CART__criterion': ['gini', 'entropy'],\n",
        "    'CART__max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'CART__min_samples_split': [2, 5, 10],\n",
        "    'CART__min_samples_leaf': [1, 2, 4],\n",
        "    'CART__max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Prepara e executa o GridSearchCV\n",
        "for name, model in pipelines:\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Resultado: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimização do Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: Voting-orig - Melhor: 0.5888 usando {}\n",
            "Modelo: Voting-padr - Melhor: 0.6138 usando {}\n",
            "Modelo: Voting-norm - Melhor: 0.5935 usando {}\n"
          ]
        }
      ],
      "source": [
        "estimators = [\n",
        "    ('logistic', LogisticRegression(max_iter=200)),\n",
        "    ('cart', DecisionTreeClassifier()),\n",
        "    ('svm', SVC())\n",
        "]\n",
        "\n",
        "pipeline_voting_orig = Pipeline(steps=[('Voting', VotingClassifier(estimators=estimators, voting='hard'))])\n",
        "pipeline_voting_padr = Pipeline(steps=[('StandardScaler', StandardScaler()), ('Voting', VotingClassifier(estimators=estimators, voting='hard'))])\n",
        "pipeline_voting_norm = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('Voting', VotingClassifier(estimators=estimators, voting='hard'))])\n",
        "\n",
        "# VotingClassifier geralmente não tem parâmetros próprios úteis para otimização nesse contexto\n",
        "param_grid_voting = {}\n",
        "\n",
        "for pipeline, label in zip([pipeline_voting_orig, pipeline_voting_padr, pipeline_voting_norm], ['orig', 'padr', 'norm']):\n",
        "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid_voting, scoring='accuracy', cv=5)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Modelo: Voting-{label} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUpaYcwDRDt"
      },
      "source": [
        "## Finalização do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Texto do pq escoli o medelo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbrFxAbSDVIj",
        "outputId": "df342c7f-1d94-4d1c-e197-0738764b9c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste (Bagging com StandardScaler): 0.721875\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "# Aplicar o scaler nos dados\n",
        "scaledX_train = scaler.transform(X_train)\n",
        "scaledX_test = scaler.transform(X_test)\n",
        "\n",
        "# Criar o modelo Bagging com DecisionTree como base\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100)\n",
        "model.fit(scaledX_train, y_train)\n",
        "\n",
        "# Fazer predições e avaliar\n",
        "predictions = model.predict(scaledX_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(f\"Acurácia no conjunto de teste (Bagging com StandardScaler): {accuracy:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "iGeQHmeg4ziu",
        "outputId": "f44bebc4-f68b-44fa-ee5d-39959078fab4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;BaggingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.BaggingClassifier.html\">?<span>Documentation for BaggingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preparação do modelo com TODO o dataset\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqzfE5wabZ4E"
      },
      "source": [
        "### Salvando o arquivo pkl como um Pipeline contendo o modelo e o scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vGBPX-zkHkfd",
        "outputId": "dc19ebfa-36d8-42b9-d1e1-ec98b27556d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste (Bagging com StandardScaler): 0.721875\n"
          ]
        }
      ],
      "source": [
        "# Treinar o scaler no conjunto de treino\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "# Aplicar o scaler nos dados\n",
        "scaledX_train = scaler.transform(X_train)\n",
        "scaledX_test = scaler.transform(X_test)\n",
        "\n",
        "# Criar o modelo Bagging com DecisionTree como base\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100)\n",
        "model.fit(scaledX_train, y_train)\n",
        "\n",
        "# Criar pipeline com scaler e modelo\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('StandardScaler', StandardScaler()),\n",
        "    ('Bagging', model)\n",
        "])\n",
        "\n",
        "# Treinar pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições e avaliar\n",
        "predictions = model.predict(scaledX_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(f\"Acurácia no conjunto de teste (Bagging com StandardScaler): {accuracy:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5Ng1e6jRbX-C",
        "outputId": "07e15359-1a21-44eb-95a5-75931202d18a"
      },
      "outputs": [],
      "source": [
        "# Salvar o modelo\n",
        "model_filename = 'bag_wine_model.pkl'\n",
        "with open(\"../models/\" + model_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "# Salvar o scaler\n",
        "scaler_filename = 'scaler_wine.pkl'\n",
        "with open(\"../scalers/\" + scaler_filename, 'wb') as file:\n",
        "    pickle.dump(scaler, file)\n",
        "\n",
        "# Salvar o pipeline (scaler + modelo)\n",
        "pipeline_filename = 'pipeline_wine_svm.pkl'\n",
        "with open(\"../pipelines/\" + pipeline_filename, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
